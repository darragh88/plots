{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeae0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# gnn_experiment.py\n",
    "# ======================================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Dict, Any, Optional, Union, List\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# ------------------------------------------------------------- optional\n",
    "try:\n",
    "    import yaml\n",
    "except ImportError:   # YAML is optional; JSON works out-of-the-box\n",
    "    yaml = None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Configuration object\n",
    "# ----------------------------------------------------------------------\n",
    "@dataclass\n",
    "class GNNConfig:\n",
    "    # --- task / model --------------------------------------------------\n",
    "    task: str            = \"node_reg\"               # {\"node_reg\", \"node_clf\", \"edge_clf\"}\n",
    "    model_name: str      = \"gcn\"                    # {\"gcn\", \"graphsage\", \"gat\", \"gatv2\"}\n",
    "    num_layers: int      = 2\n",
    "    hidden_dim: int      = 128\n",
    "    heads: int           = 8                        # for attention models\n",
    "    norm: str            = \"batch\"                  # {\"batch\", \"layer\", None}\n",
    "\n",
    "    # --- dataset & target ---------------------------------------------\n",
    "    target_col: str      = \"target\"                 # node column to predict\n",
    "\n",
    "    # --- data splitting -----------------------------------------------\n",
    "    split_mode: str      = \"date\"                   # {\"date\", \"ratio\"}\n",
    "    cutoff_date: Optional[str] = None               # required if split_mode == \"date\"\n",
    "    val_ratio: float     = 0.10                     # used if split_mode == \"ratio\"\n",
    "    test_ratio: float    = 0.10                     # used if split_mode == \"ratio\"\n",
    "    shuffle_in_split: bool = False                  # shuffle batches inside DataLoader?\n",
    "\n",
    "    # --- optimisation --------------------------------------------------\n",
    "    batch_size: int      = 32\n",
    "    lr: float            = 1e-3\n",
    "    epochs: int          = 100\n",
    "    patience: int        = 10\n",
    "    grad_clip: float     = 1.0\n",
    "\n",
    "    # --- loss / optimiser ---------------------------------------------\n",
    "    loss_fn: str         = \"mse\"                    # {\"mse\", \"mae\", \"bce\", \"cross_entropy\"}\n",
    "    class_weights: Optional[list] = None            # for BCE / CE\n",
    "    optimiser: str       = \"adam\"                   # {\"adam\", \"adamw\", \"sgd\"}\n",
    "    optimiser_kwargs: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    # --- misc ----------------------------------------------------------\n",
    "    device: str          = \"cuda\"                   # fallback to cpu if unavailable\n",
    "    run_name: str        = \"default_run\"\n",
    "    seed: int            = 42\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # helper constructor\n",
    "    @staticmethod\n",
    "    def load(cfg: Union[\"GNNConfig\", str, Dict[str, Any]]) -> \"GNNConfig\":\n",
    "        \"\"\"\n",
    "        Accept a GNNConfig, a dict, or a path to JSON/YAML and return a GNNConfig.\n",
    "        \"\"\"\n",
    "        if isinstance(cfg, GNNConfig):\n",
    "            return cfg\n",
    "        if isinstance(cfg, dict):\n",
    "            return GNNConfig(**cfg)\n",
    "        if isinstance(cfg, (str, pathlib.Path)):\n",
    "            path = pathlib.Path(cfg)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                if path.suffix == \".json\":\n",
    "                    data = json.load(f)\n",
    "                elif path.suffix in {\".yml\", \".yaml\"} and yaml is not None:\n",
    "                    data = yaml.safe_load(f)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported file type for config path\")\n",
    "            return GNNConfig(**data)\n",
    "        raise TypeError(f\"Unsupported cfg type: {type(cfg)}\")\n",
    "\n",
    "    # pretty-print helper\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Core experiment wrapper\n",
    "# ----------------------------------------------------------------------\n",
    "class GNNExperiment:\n",
    "    \"\"\"\n",
    "    End-to-end wrapper around:\n",
    "       raw node/edge time-series  →  PyG snapshots  →  loaders  →  model\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------ constructor -------------------------------------------------\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_frames: Dict[str, pd.DataFrame],\n",
    "        edge_frames: Dict[str, pd.DataFrame],\n",
    "        graph: nx.DiGraph,\n",
    "        cfg: Union[GNNConfig, str, Dict[str, Any]] = GNNConfig(),\n",
    "    ):\n",
    "        # raw inputs\n",
    "        self.node_frames = node_frames     # {\"Tokyo\": df, ...}\n",
    "        self.edge_frames = edge_frames     # {\"tokyo-chubu\": df, ...}\n",
    "        self.graph       = graph\n",
    "\n",
    "        # config\n",
    "        self.cfg: GNNConfig = GNNConfig.load(cfg)\n",
    "\n",
    "        # runtime placeholders\n",
    "        self.reg_order:  List[str]     = []   # alphabetical node order\n",
    "        self.edge_order: List[tuple]   = []   # (src_idx, dst_idx)\n",
    "        self.snapshots   = None               # list[Data]\n",
    "\n",
    "        self.train_dl = self.val_dl = self.test_dl = None\n",
    "\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.loss_fn = None\n",
    "        self.history: Dict[str, list] = {}\n",
    "\n",
    "        # device handling\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if (self.cfg.device == \"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
    "        )\n",
    "\n",
    "    # =========================== helpers =====================================\n",
    "    @staticmethod\n",
    "    def _edge_key(src: str, dst: str) -> str:\n",
    "        \"\"\"Convert (src, dst) into canonical 'src-dst' lowercase key.\"\"\"\n",
    "        return f\"{src}-{dst}\".lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_same_index(idxs: List[pd.DatetimeIndex]) -> List[pd.Timestamp]:\n",
    "        \"\"\"Return sorted intersection of all DatetimeIndex objects.\"\"\"\n",
    "        common = sorted(set.intersection(*(set(i) for i in idxs)))\n",
    "        if not common:\n",
    "            raise ValueError(\"No common timestamps across supplied DataFrames\")\n",
    "        return common\n",
    "\n",
    "    # =================== 1. snapshot creation ================================\n",
    "    def prepare_snapshots(self) -> \"GNNExperiment\":\n",
    "        \"\"\"\n",
    "        Build `torch_geometric.data.Data` objects for each shared timestamp.\n",
    "        Stores them in `self.snapshots` and returns self.\n",
    "        \"\"\"\n",
    "        # --- deterministic node order ----------------------------------------\n",
    "        self.reg_order = sorted(self.graph.nodes)\n",
    "        node_pos = {n: i for i, n in enumerate(self.reg_order)}\n",
    "\n",
    "        # --- deterministic edge order ----------------------------------------\n",
    "        self.edge_order = [(node_pos[src], node_pos[dst])\n",
    "                           for (src, dst) in self.graph.edges]\n",
    "\n",
    "        # --- intersect timestamps --------------------------------------------\n",
    "        node_idxs = [df.index for df in self.node_frames.values()]\n",
    "        edge_idxs = [df.index for df in self.edge_frames.values()]\n",
    "        ts_common = self._ensure_same_index(node_idxs + edge_idxs)\n",
    "\n",
    "        # --- construct snapshot objects --------------------------------------\n",
    "        snapshots: List[Data] = []\n",
    "        for ts in ts_common:\n",
    "            # ---- node matrix & targets\n",
    "            feats, tgts = [], []\n",
    "            for region in self.reg_order:\n",
    "                row = self.node_frames[region].loc[ts]\n",
    "                tgts.append(row[self.cfg.target_col])\n",
    "                feats.append(row.drop(self.cfg.target_col).to_numpy(dtype=np.float32))\n",
    "            x = torch.tensor(np.vstack(feats), dtype=torch.float32)\n",
    "            y = torch.tensor(tgts, dtype=torch.float32)\n",
    "\n",
    "            # ---- edge attribute matrix\n",
    "            edge_rows = []\n",
    "            for src_idx, dst_idx in self.edge_order:\n",
    "                src_name, dst_name = self.reg_order[src_idx], self.reg_order[dst_idx]\n",
    "                key = self._edge_key(src_name, dst_name)\n",
    "                row = self.edge_frames[key].loc[ts]\n",
    "                edge_rows.append(row.to_numpy(dtype=np.float32))\n",
    "            edge_attr = torch.tensor(np.vstack(edge_rows), dtype=torch.float32)\n",
    "\n",
    "            # ---- edge index tensor (shape [2, E])\n",
    "            edge_index = torch.tensor(np.vstack(self.edge_order), dtype=torch.long)\n",
    "\n",
    "            snapshots.append(\n",
    "                Data(\n",
    "                    x=x,\n",
    "                    edge_index=edge_index,\n",
    "                    edge_attr=edge_attr,\n",
    "                    y=y,\n",
    "                    snap_time=torch.tensor([pd.Timestamp(ts).value]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.snapshots = snapshots\n",
    "        return self\n",
    "\n",
    "    # =================== 2. build loaders ====================================\n",
    "    def build_loaders(self) -> \"GNNExperiment\":\n",
    "        \"\"\"\n",
    "        Create `train_dl`, `val_dl`, `test_dl` according to `self.cfg`.\n",
    "        Must be called **after** `prepare_snapshots`.\n",
    "        \"\"\"\n",
    "        if self.snapshots is None:\n",
    "            raise RuntimeError(\"Call prepare_snapshots() before build_loaders()\")\n",
    "\n",
    "        # ---- chronological sort (snap_time is 1-elem tensor) -----------------\n",
    "        snaps_sorted = sorted(self.snapshots, key=lambda g: g.snap_time.item())\n",
    "\n",
    "        if self.cfg.split_mode == \"date\":\n",
    "            if self.cfg.cutoff_date is None:\n",
    "                raise ValueError(\"`cutoff_date` must be set in cfg for date split\")\n",
    "\n",
    "            cutoff_int = pd.Timestamp(self.cfg.cutoff_date).value\n",
    "            train_set = [g for g in snaps_sorted if g.snap_time.item() <= cutoff_int]\n",
    "            holdout   = [g for g in snaps_sorted if g.snap_time.item() >  cutoff_int]\n",
    "\n",
    "            if not holdout:\n",
    "                raise ValueError(\"No snapshots after cutoff_date for val/test split\")\n",
    "\n",
    "            # simple 50-50 val/test split on holdout\n",
    "            mid = len(holdout) // 2\n",
    "            val_set, test_set = holdout[:mid], holdout[mid:]\n",
    "\n",
    "        elif self.cfg.split_mode == \"ratio\":\n",
    "            n_total = len(snaps_sorted)\n",
    "            n_test  = int(n_total * self.cfg.test_ratio)\n",
    "            n_val   = int(n_total * self.cfg.val_ratio)\n",
    "            n_train = n_total - n_val - n_test\n",
    "\n",
    "            train_set = snaps_sorted[:n_train]\n",
    "            val_set   = snaps_sorted[n_train:n_train + n_val]\n",
    "            test_set  = snaps_sorted[n_train + n_val:]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split_mode '{self.cfg.split_mode}'\")\n",
    "\n",
    "        # ---- DataLoaders ------------------------------------------------------\n",
    "        self.train_dl = DataLoader(\n",
    "            train_set,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            shuffle=self.cfg.shuffle_in_split,\n",
    "        )\n",
    "        self.val_dl = DataLoader(\n",
    "            val_set,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        self.test_dl = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    # =================== placeholders for later ==============================\n",
    "    def init_model(self) -> \"GNNExperiment\":\n",
    "        \"\"\"Instantiate the requested GNN backbone + head (TODO).\"\"\"\n",
    "        # TODO\n",
    "        return self\n",
    "\n",
    "    def compile(self) -> \"GNNExperiment\":\n",
    "        \"\"\"Attach loss fn, optimiser, schedulers, etc. (TODO).\"\"\"\n",
    "        # TODO\n",
    "        return self\n",
    "\n",
    "    def train(self, debug: bool = False):\n",
    "        \"\"\"Main training loop (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, split: str = \"val\") -> Dict[str, float]:\n",
    "        \"\"\"Evaluate on a chosen split (TODO).\"\"\"\n",
    "        # TODO\n",
    "        return {}\n",
    "\n",
    "    def predict(self, node_frames_new, edge_frames_new, timestamps):\n",
    "        \"\"\"Predict on unseen timestamps (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def plot_history(self, metric: str = \"loss\"):\n",
    "        \"\"\"Matplotlib learning-curve plot (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def save(self, run_dir: Union[str, pathlib.Path]):\n",
    "        \"\"\"Save config, weights, scaler, etc. (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, run_dir: Union[str, pathlib.Path]) -> \"GNNExperiment\":\n",
    "        \"\"\"Reload a previously saved experiment (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f170a7",
   "metadata": {},
   "source": [
    "### Model zoo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41969e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModelSimple(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(d_in, hidden)\n",
    "        self.conv2 = GCNConv(hidden, hidden)\n",
    "        self.fc    = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x, ei, batch = data.x, data.edge_index, data.batch\n",
    "        x = torch.relu(self.conv1(x, ei))\n",
    "        x = torch.relu(self.conv2(x, ei))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.fc(x)\n",
    "\n",
    "class GNNConv(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers):\n",
    "        super().__init__()\n",
    "        self.body = GCN(d_in, hidden, layers, norm='batch', act='relu')\n",
    "        self.fc   = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x = self.body(data.x, data.edge_index)\n",
    "        return self.fc(x)\n",
    "\n",
    "class GNNSage(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers):\n",
    "        super().__init__()\n",
    "        self.body = GraphSAGE(d_in, hidden, layers, norm='batch', act='relu')\n",
    "        self.fc   = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x = self.body(data.x, data.edge_index)\n",
    "        return self.fc(x)\n",
    "\n",
    "class GNNGAT(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers, heads):\n",
    "        super().__init__()\n",
    "        self.body = GAT(d_in, hidden, layers, heads=heads, norm='batch', act='relu')\n",
    "        self.fc   = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x = self.body(data.x, data.edge_index)\n",
    "        return self.fc(x)\n",
    "\n",
    "class GNNGAT2(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers, heads, edge_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(d_in, hidden, heads=heads, concat=True,  edge_dim=edge_dim)\n",
    "        self.conv2 = GATv2Conv(hidden*heads, hidden, heads=1,  concat=False, edge_dim=edge_dim)\n",
    "        self.fc    = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x = torch.relu(self.conv1(data.x, data.edge_index, data.edge_attr))\n",
    "        x = torch.relu(self.conv2(x,       data.edge_index, data.edge_attr))\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092c183",
   "metadata": {},
   "source": [
    "### Initialize Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca22dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.  EXPERIMENT  (unchanged until indicated)\n",
    "class GNNExperiment:\n",
    "    # (constructor, helpers, prepare_snapshots, build_loaders as in previous post)\n",
    "    #  …  previous code unchanged …\n",
    "\n",
    "    # ---------- NEW: model factory ------------------------------------\n",
    "    def init_model(self) -> \"GNNExperiment\":\n",
    "        if self.snapshots is None:\n",
    "            raise RuntimeError(\"Call prepare_snapshots() first.\")\n",
    "\n",
    "        d_in  = self.snapshots[0].x.shape[1]\n",
    "        d_out = 1                               # can be generalised later\n",
    "        edge_dim = (\n",
    "            self.snapshots[0].edge_attr.shape[1]\n",
    "            if self.snapshots[0].edge_attr is not None else None\n",
    "        )\n",
    "\n",
    "        name = self.cfg.model_name.lower()\n",
    "        if name in {\"simple\", \"baseline\"}:\n",
    "            model = GNNModelSimple(d_in, self.cfg.hidden_dim, d_out)\n",
    "        elif name in {\"gcn\"}:\n",
    "            model = GNNConv(d_in, self.cfg.hidden_dim, d_out, self.cfg.num_layers)\n",
    "        elif name in {\"graphsage\", \"sage\"}:\n",
    "            model = GNNSage(d_in, self.cfg.hidden_dim, d_out, self.cfg.num_layers)\n",
    "        elif name == \"gat\":\n",
    "            model = GNNGAT(d_in, self.cfg.hidden_dim, d_out,\n",
    "                           self.cfg.num_layers, self.cfg.heads)\n",
    "        elif name in {\"gatv2\", \"gat2\"}:\n",
    "            if edge_dim is None:\n",
    "                raise ValueError(\"GATv2 selected but snapshots contain no edge features.\")\n",
    "            model = GNNGAT2(d_in, self.cfg.hidden_dim, d_out,\n",
    "                            self.cfg.num_layers, self.cfg.heads, edge_dim)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model_name '{self.cfg.model_name}'\")\n",
    "\n",
    "        self.model = model.to(self.device)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0d8ec",
   "metadata": {},
   "source": [
    "### Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b13297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile(self) -> \"GNNExperiment\":\n",
    "    \"\"\"\n",
    "    Attach loss function, optimiser (and later scheduler) to the experiment.\n",
    "    Must be called **after** init_model().\n",
    "    \"\"\"\n",
    "    if self.model is None:\n",
    "        raise RuntimeError(\"Call init_model() before compile()\")\n",
    "\n",
    "    # ---------- LOSS ------------------------------------------------\n",
    "    loss_name = self.cfg.loss_fn.lower()\n",
    "    if loss_name == \"mse\":\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "    elif loss_name in {\"mae\", \"l1\"}:\n",
    "        self.loss_fn = torch.nn.L1Loss()\n",
    "    elif loss_name == \"bce\":\n",
    "        pos_w = (\n",
    "            torch.tensor(self.cfg.class_weights, dtype=torch.float32, device=self.device)\n",
    "            if self.cfg.class_weights else None\n",
    "        )\n",
    "        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_w)\n",
    "    elif loss_name in {\"cross_entropy\", \"ce\"}:\n",
    "        w = (\n",
    "            torch.tensor(self.cfg.class_weights, dtype=torch.float32, device=self.device)\n",
    "            if self.cfg.class_weights else None\n",
    "        )\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(weight=w)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss_fn '{self.cfg.loss_fn}'\")\n",
    "\n",
    "    # ---------- OPTIMISER ------------------------------------------\n",
    "    opt_name = self.cfg.optimiser.lower()\n",
    "    opt_kwargs = dict(lr=self.cfg.lr, **self.cfg.optimiser_kwargs)\n",
    "\n",
    "    if opt_name == \"adam\":\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), **opt_kwargs)\n",
    "    elif opt_name == \"adamw\":\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), **opt_kwargs)\n",
    "    elif opt_name == \"sgd\":\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), **opt_kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimiser '{self.cfg.optimiser}'\")\n",
    "\n",
    "    # schedulers or other callbacks could be attached here later\n",
    "    return self\n",
    "\n",
    "# ---------- train / evaluate / etc. to be filled later ----------\n",
    "def train(self, debug: bool = False):\n",
    "    pass\n",
    "def evaluate(self, split: str = \"val\") -> Dict[str, float]:\n",
    "    return {}\n",
    "def predict(self, node_frames_new, edge_frames_new, timestamps):\n",
    "    pass\n",
    "def plot_history(self, metric: str = \"loss\"): pass\n",
    "def save(self, run_dir: Union[str, pathlib.Path]): pass\n",
    "@classmethod\n",
    "def load(cls, run_dir: Union[str, pathlib.Path]) -> \"GNNExperiment\": pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55c795c",
   "metadata": {},
   "source": [
    "### Extra Loss functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee67715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.  SMALL UTILS\n",
    "# ----------------------------------------------------------------------\n",
    "def mean_absolute_error(preds: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "    \"\"\"MAE helper (tensor → float CPU).\"\"\"\n",
    "    return torch.mean(torch.abs(preds - targets)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# gnn_experiment.py\n",
    "# ======================================================================\n",
    "from __future__ import annotations\n",
    "import json, pathlib, numpy as np, pandas as pd, torch, networkx as nx\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Dict, Any, Optional, Union, List\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv, GATv2Conv, GCN, GraphSAGE, GAT, global_mean_pool\n",
    ")\n",
    "\n",
    "try:  import yaml\n",
    "except ImportError: yaml = None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  SMALL UTILS\n",
    "# ----------------------------------------------------------------------\n",
    "def mean_absolute_error(preds: torch.Tensor, targets: torch.Tensor) -> float:\n",
    "    return torch.mean(torch.abs(preds - targets)).item()\n",
    "\n",
    "def has_nan(t: torch.Tensor) -> bool:\n",
    "    return torch.isnan(t).any() or torch.isinf(t).any()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  CONFIG\n",
    "# ----------------------------------------------------------------------\n",
    "@dataclass\n",
    "class GNNConfig:\n",
    "    # --- task / model --------------------------------------------------\n",
    "    task: str            = \"node_reg\"              # {\"node_reg\", \"node_clf\", \"edge_clf\"}\n",
    "    model_name: str      = \"gcn\"                   # {\"simple\",\"gcn\",\"graphsage\",\"gat\",\"gatv2\"}\n",
    "    num_layers: int      = 2\n",
    "    hidden_dim: int      = 128\n",
    "    heads: int           = 8\n",
    "    norm: str            = \"batch\"\n",
    "\n",
    "    # --- dataset & target ---------------------------------------------\n",
    "    target_col: str      = \"target\"\n",
    "\n",
    "    # --- splitting -----------------------------------------------------\n",
    "    split_mode: str      = \"date\"                  # {\"date\",\"ratio\"}\n",
    "    cutoff_date: Optional[str] = None\n",
    "    val_ratio: float     = 0.10\n",
    "    test_ratio: float    = 0.10\n",
    "    shuffle_in_split: bool = False\n",
    "\n",
    "    # --- optimisation --------------------------------------------------\n",
    "    batch_size: int      = 32\n",
    "    lr: float            = 1e-3\n",
    "    epochs: int          = 100\n",
    "    patience: int        = 10\n",
    "    grad_clip: float     = 1.0\n",
    "\n",
    "    # --- loss / optimiser ---------------------------------------------\n",
    "    loss_fn: str         = \"mse\"                   # {\"mse\",\"mae\",\"bce\",\"cross_entropy\"}\n",
    "    class_weights: Optional[list] = None\n",
    "    optimiser: str       = \"adam\"                  # {\"adam\",\"adamw\",\"sgd\"}\n",
    "    optimiser_kwargs: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    # --- misc ----------------------------------------------------------\n",
    "    device: str          = \"cuda\"\n",
    "    run_name: str        = \"default_run\"\n",
    "    seed: int            = 42\n",
    "\n",
    "    # ---------- helper constructor ----------\n",
    "    @staticmethod\n",
    "    def load(cfg: Union[\"GNNConfig\", str, Dict[str, Any]]) -> \"GNNConfig\":\n",
    "        if isinstance(cfg, GNNConfig):\n",
    "            return cfg\n",
    "        if isinstance(cfg, dict):\n",
    "            return GNNConfig(**cfg)\n",
    "        path = pathlib.Path(cfg)\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = (\n",
    "                json.load(f)\n",
    "                if path.suffix == \".json\"\n",
    "                else yaml.safe_load(f) if yaml else\n",
    "                (_ for _ in ()).throw(RuntimeError(\"PyYAML not installed\"))\n",
    "            )\n",
    "        return GNNConfig(**data)\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  MODEL ZOO  (shortened comments)\n",
    "# ----------------------------------------------------------------------\n",
    "class GNNModelSimple(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(d_in, hidden)\n",
    "        self.conv2 = GCNConv(hidden, hidden)\n",
    "        self.fc    = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x = torch.relu(self.conv1(data.x, data.edge_index))\n",
    "        x = torch.relu(self.conv2(x,      data.edge_index))\n",
    "        return self.fc(global_mean_pool(x, data.batch))\n",
    "\n",
    "class GNNConv(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers):\n",
    "        super().__init__()\n",
    "        self.body = GCN(d_in, hidden, layers, norm='batch', act='relu')\n",
    "        self.fc   = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        return self.fc(self.body(data.x, data.edge_index))\n",
    "\n",
    "class GNNSage(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers):\n",
    "        super().__init__()\n",
    "        self.body = GraphSAGE(d_in, hidden, layers, norm='batch', act='relu')\n",
    "        self.fc   = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        return self.fc(self.body(data.x, data.edge_index))\n",
    "\n",
    "class GNNGAT(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers, heads):\n",
    "        super().__init__()\n",
    "        self.body = GAT(d_in, hidden, layers, heads=heads, norm='batch', act='relu')\n",
    "        self.fc   = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        return self.fc(self.body(data.x, data.edge_index))\n",
    "\n",
    "class GNNGAT2(torch.nn.Module):\n",
    "    def __init__(self, d_in, hidden, d_out, layers, heads, edge_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(d_in, hidden, heads=heads, concat=True, edge_dim=edge_dim)\n",
    "        self.conv2 = GATv2Conv(hidden*heads, hidden, heads=1, concat=False, edge_dim=edge_dim)\n",
    "        self.fc    = torch.nn.Linear(hidden, d_out)\n",
    "    def forward(self, data):\n",
    "        x = torch.relu(self.conv1(data.x, data.edge_index, data.edge_attr))\n",
    "        x = torch.relu(self.conv2(x,      data.edge_index, data.edge_attr))\n",
    "        return self.fc(global_mean_pool(x, data.batch))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3.  EXPERIMENT (prepare_snapshots + loaders + model/compile as before)\n",
    "# ----------------------------------------------------------------------\n",
    "class GNNExperiment:\n",
    "    # ------- constructor & helpers (unchanged until train section) -----\n",
    "    def __init__(self, node_frames, edge_frames, graph, cfg=GNNConfig()):\n",
    "        self.node_frames, self.edge_frames, self.graph = node_frames, edge_frames, graph\n",
    "        self.cfg: GNNConfig = GNNConfig.load(cfg)\n",
    "\n",
    "        self.reg_order:  List[str]   = []\n",
    "        self.edge_order: List[tuple] = []\n",
    "        self.snapshots = None\n",
    "\n",
    "        self.train_dl = self.val_dl = self.test_dl = None\n",
    "        self.model = self.optimizer = self.loss_fn = None\n",
    "        self.metric_fn = mean_absolute_error\n",
    "        self.history: Dict[str, list] = {\"train_loss\": [], \"val_loss\": [], \"val_metric\": []}\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.patience_counter = 0\n",
    "        self.best_ckpt = None\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if (self.cfg.device == \"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
    "        )\n",
    "\n",
    "    # -- (prepare_snapshots & build_loaders identical to earlier version) --\n",
    "\n",
    "    def _edge_key(self, s, d): return f\"{s}-{d}\".lower()\n",
    "    @staticmethod\n",
    "    def _ensure_same_index(idxs): return sorted(set.intersection(*(set(i) for i in idxs)))\n",
    "\n",
    "    def prepare_snapshots(self):\n",
    "        self.reg_order = sorted(self.graph.nodes)\n",
    "        pos = {n: i for i, n in enumerate(self.reg_order)}\n",
    "        self.edge_order = [(pos[s], pos[d]) for (s, d) in self.graph.edges]\n",
    "\n",
    "        ts_common = self._ensure_same_index(\n",
    "            [df.index for df in self.node_frames.values()]\n",
    "            + [df.index for df in self.edge_frames.values()]\n",
    "        )\n",
    "\n",
    "        snaps = []\n",
    "        for ts in ts_common:\n",
    "            feats, tgts = [], []\n",
    "            for region in self.reg_order:\n",
    "                row = self.node_frames[region].loc[ts]\n",
    "                tgts.append(row[self.cfg.target_col])\n",
    "                feats.append(row.drop(self.cfg.target_col).to_numpy(dtype=np.float32))\n",
    "            x = torch.tensor(np.vstack(feats), dtype=torch.float32)\n",
    "            y = torch.tensor(tgts, dtype=torch.float32)\n",
    "\n",
    "            edge_rows = []\n",
    "            for s_i, d_i in self.edge_order:\n",
    "                s, d = self.reg_order[s_i], self.reg_order[d_i]\n",
    "                edge_rows.append(\n",
    "                    self.edge_frames[self._edge_key(s, d)].loc[ts].to_numpy(np.float32)\n",
    "                )\n",
    "            edge_attr  = torch.tensor(np.vstack(edge_rows), dtype=torch.float32)\n",
    "            edge_index = torch.tensor(np.vstack(self.edge_order), dtype=torch.long)\n",
    "\n",
    "            snaps.append(\n",
    "                Data(x=x, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                     y=y, snap_time=torch.tensor([pd.Timestamp(ts).value]))\n",
    "            )\n",
    "        self.snapshots = snaps\n",
    "        return self\n",
    "\n",
    "    def build_loaders(self):\n",
    "        if self.snapshots is None:\n",
    "            raise RuntimeError(\"Call prepare_snapshots() first\")\n",
    "\n",
    "        snaps_sorted = sorted(self.snapshots, key=lambda g: g.snap_time.item())\n",
    "        if self.cfg.split_mode == \"date\":\n",
    "            cut = pd.Timestamp(self.cfg.cutoff_date).value\n",
    "            train_set = [g for g in snaps_sorted if g.snap_time.item() <= cut]\n",
    "            hold      = [g for g in snaps_sorted if g.snap_time.item() >  cut]\n",
    "            mid = len(hold) // 2\n",
    "            val_set, test_set = hold[:mid], hold[mid:]\n",
    "        else:\n",
    "            n = len(snaps_sorted)\n",
    "            n_test = int(n * self.cfg.test_ratio)\n",
    "            n_val  = int(n * self.cfg.val_ratio)\n",
    "            n_train = n - n_val - n_test\n",
    "            train_set = snaps_sorted[:n_train]\n",
    "            val_set   = snaps_sorted[n_train:n_train+n_val]\n",
    "            test_set  = snaps_sorted[n_train+n_val:]\n",
    "\n",
    "        self.train_dl = DataLoader(train_set, batch_size=self.cfg.batch_size,\n",
    "                                   shuffle=self.cfg.shuffle_in_split)\n",
    "        self.val_dl   = DataLoader(val_set,   batch_size=self.cfg.batch_size)\n",
    "        self.test_dl  = DataLoader(test_set,  batch_size=self.cfg.batch_size)\n",
    "        return self\n",
    "\n",
    "    def update_config(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if not hasattr(self.cfg, k): raise AttributeError(k)\n",
    "            setattr(self.cfg, k, v)\n",
    "        return self\n",
    "\n",
    "    def init_model(self):\n",
    "        d_in  = self.snapshots[0].x.shape[1]\n",
    "        d_out = 1\n",
    "        edge_dim = self.snapshots[0].edge_attr.shape[1]\n",
    "\n",
    "        name = self.cfg.model_name.lower()\n",
    "        if name in {\"simple\", \"baseline\"}:\n",
    "            self.model = GNNModelSimple(d_in, self.cfg.hidden_dim, d_out)\n",
    "        elif name == \"gcn\":\n",
    "            self.model = GNNConv(d_in, self.cfg.hidden_dim, d_out, self.cfg.num_layers)\n",
    "        elif name in {\"graphsage\", \"sage\"}:\n",
    "            self.model = GNNSage(d_in, self.cfg.hidden_dim, d_out, self.cfg.num_layers)\n",
    "        elif name == \"gat\":\n",
    "            self.model = GNNGAT(d_in, self.cfg.hidden_dim, d_out,\n",
    "                                self.cfg.num_layers, self.cfg.heads)\n",
    "        elif name in {\"gatv2\", \"gat2\"}:\n",
    "            self.model = GNNGAT2(d_in, self.cfg.hidden_dim, d_out,\n",
    "                                 self.cfg.num_layers, self.cfg.heads, edge_dim)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model '{self.cfg.model_name}'\")\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        return self\n",
    "\n",
    "    def compile(self):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Call init_model() before compile()\")\n",
    "\n",
    "        loss = self.cfg.loss_fn.lower()\n",
    "        if loss == \"mse\":\n",
    "            self.loss_fn = torch.nn.MSELoss()\n",
    "        elif loss in {\"mae\", \"l1\"}:\n",
    "            self.loss_fn = torch.nn.L1Loss()\n",
    "        elif loss == \"bce\":\n",
    "            w = (torch.tensor(self.cfg.class_weights, dtype=torch.float32, device=self.device)\n",
    "                 if self.cfg.class_weights else None)\n",
    "            self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=w)\n",
    "        elif loss in {\"cross_entropy\", \"ce\"}:\n",
    "            w = (torch.tensor(self.cfg.class_weights, dtype=torch.float32, device=self.device)\n",
    "                 if self.cfg.class_weights else None)\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss(weight=w)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown loss_fn '{self.cfg.loss_fn}'\")\n",
    "\n",
    "        opt_name = self.cfg.optimiser.lower()\n",
    "        opt_kwargs = dict(lr=self.cfg.lr, **self.cfg.optimiser_kwargs)\n",
    "        if opt_name == \"adam\":\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), **opt_kwargs)\n",
    "        elif opt_name == \"adamw\":\n",
    "            self.optimizer = torch.optim.AdamW(self.model.parameters(), **opt_kwargs)\n",
    "        elif opt_name == \"sgd\":\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), **opt_kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimiser '{self.cfg.optimiser}'\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    # ==================================================================\n",
    "    # ### 4. TRAIN / EVALUATE ###########################################\n",
    "    # ==================================================================\n",
    "    def _train_epoch(self, debug: bool = False) -> float:\n",
    "        self.model.train()\n",
    "        total = 0\n",
    "        for step, data in enumerate(self.train_dl):\n",
    "            data = data.to(self.device)\n",
    "            data.x = data.x.float()\n",
    "            if data.edge_attr is not None:\n",
    "                data.edge_attr = data.edge_attr.float()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self.model(data)\n",
    "            loss = self.loss_fn(out.squeeze(-1), data.y)\n",
    "            if debug and (has_nan(loss) or has_nan(out)):\n",
    "                raise RuntimeError(f\"NaN detected at step {step}\")\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg.grad_clip)\n",
    "            self.optimizer.step()\n",
    "            total += loss.item()\n",
    "        return total / len(self.train_dl)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _eval_loader(self, loader: DataLoader) -> tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        total_loss = total_metric = 0\n",
    "        for data in loader:\n",
    "            data = data.to(self.device)\n",
    "            data.x = data.x.float()\n",
    "            if data.edge_attr is not None:\n",
    "                data.edge_attr = data.edge_attr.float()\n",
    "            out = self.model(data)\n",
    "            loss = self.loss_fn(out.squeeze(-1), data.y)\n",
    "            metric = self.metric_fn(out.squeeze(-1).cpu(), data.y.cpu())\n",
    "            total_loss   += loss.item()\n",
    "            total_metric += metric\n",
    "        n = len(loader)\n",
    "        return total_loss / n, total_metric / n\n",
    "\n",
    "    def train(self, debug: bool = False):\n",
    "        if any(v is None for v in (self.model, self.optimizer, self.loss_fn)):\n",
    "            raise RuntimeError(\"Call init_model() and compile() before train()\")\n",
    "\n",
    "        for epoch in range(1, self.cfg.epochs + 1):\n",
    "            tr_loss = self._train_epoch(debug)\n",
    "            val_loss, val_metric = self._eval_loader(self.val_dl)\n",
    "\n",
    "            self.history[\"train_loss\"].append(tr_loss)\n",
    "            self.history[\"val_loss\"].append(val_loss)\n",
    "            self.history[\"val_metric\"].append(val_metric)\n",
    "\n",
    "            print(f\"[{epoch:03d}/{self.cfg.epochs}] \"\n",
    "                  f\"train={tr_loss:.4f}  val={val_loss:.4f}  metric={val_metric:.4f}\")\n",
    "\n",
    "            # ----- early stopping -----\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                self.patience_counter = 0\n",
    "                self.best_ckpt = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                if self.patience_counter >= self.cfg.patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "        return self\n",
    "\n",
    "    def evaluate(self, split: str = \"test\") -> Dict[str, float]:\n",
    "        loader = {\"train\": self.train_dl, \"val\": self.val_dl, \"test\": self.test_dl}.get(split)\n",
    "        if loader is None:\n",
    "            raise ValueError(\"split must be one of {'train','val','test'}\")\n",
    "\n",
    "        loss, metric = self._eval_loader(loader)\n",
    "        return {\"loss\": loss, \"metric\": metric}\n",
    "\n",
    "    # -------- stubs for predict / save / load / plot (later) ----------\n",
    "    def predict(self, node_frames_new, edge_frames_new, timestamps): ...\n",
    "    def plot_history(self, metric: str = \"loss\"): ...\n",
    "    def save(self, run_dir): ...\n",
    "    @classmethod\n",
    "    def load(cls, run_dir): ...\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# USAGE EXAMPLE (not executed here)\n",
    "# ======================================================================\n",
    "# exp = (GNNExperiment(nodes_dict, edges_dict, G, {\"model_name\":\"gatv2\", \"cutoff_date\":\"2023-06-01\"})\n",
    "#        .prepare_snapshots()\n",
    "#        .build_loaders()\n",
    "#        .init_model()\n",
    "#        .compile()\n",
    "#        .train(debug=False))\n",
    "#\n",
    "# print(exp.evaluate(\"test\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
