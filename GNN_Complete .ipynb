{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571078c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# gnn_experiment.py\n",
    "# ======================================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Dict, Any, Optional, Union, List\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# ------------------------------------------------------------- optional\n",
    "try:\n",
    "    import yaml\n",
    "except ImportError:   # YAML is optional; JSON works out-of-the-box\n",
    "    yaml = None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Configuration object\n",
    "# ----------------------------------------------------------------------\n",
    "@dataclass\n",
    "class GNNConfig:\n",
    "    # --- task / model --------------------------------------------------\n",
    "    task: str            = \"node_reg\"               # {\"node_reg\", \"node_clf\", \"edge_clf\"}\n",
    "    model_name: str      = \"gcn\"                    # {\"gcn\", \"graphsage\", \"gat\", \"gatv2\"}\n",
    "    num_layers: int      = 2\n",
    "    hidden_dim: int      = 128\n",
    "    heads: int           = 8                        # for attention models\n",
    "    norm: str            = \"batch\"                  # {\"batch\", \"layer\", None}\n",
    "\n",
    "    # --- dataset & target ---------------------------------------------\n",
    "    target_col: str      = \"target\"                 # node column to predict\n",
    "\n",
    "    # --- data splitting -----------------------------------------------\n",
    "    split_mode: str      = \"date\"                   # {\"date\", \"ratio\"}\n",
    "    cutoff_date: Optional[str] = None               # required if split_mode == \"date\"\n",
    "    val_ratio: float     = 0.10                     # used if split_mode == \"ratio\"\n",
    "    test_ratio: float    = 0.10                     # used if split_mode == \"ratio\"\n",
    "    shuffle_in_split: bool = False                  # shuffle batches inside DataLoader?\n",
    "\n",
    "    # --- optimisation --------------------------------------------------\n",
    "    batch_size: int      = 32\n",
    "    lr: float            = 1e-3\n",
    "    epochs: int          = 100\n",
    "    patience: int        = 10\n",
    "    grad_clip: float     = 1.0\n",
    "\n",
    "    # --- loss / optimiser ---------------------------------------------\n",
    "    loss_fn: str         = \"mse\"                    # {\"mse\", \"mae\", \"bce\", \"cross_entropy\"}\n",
    "    class_weights: Optional[list] = None            # for BCE / CE\n",
    "    optimiser: str       = \"adam\"                   # {\"adam\", \"adamw\", \"sgd\"}\n",
    "    optimiser_kwargs: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    # --- misc ----------------------------------------------------------\n",
    "    device: str          = \"cuda\"                   # fallback to cpu if unavailable\n",
    "    run_name: str        = \"default_run\"\n",
    "    seed: int            = 42\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # helper constructor\n",
    "    @staticmethod\n",
    "    def load(cfg: Union[\"GNNConfig\", str, Dict[str, Any]]) -> \"GNNConfig\":\n",
    "        \"\"\"\n",
    "        Accept a GNNConfig, a dict, or a path to JSON/YAML and return a GNNConfig.\n",
    "        \"\"\"\n",
    "        if isinstance(cfg, GNNConfig):\n",
    "            return cfg\n",
    "        if isinstance(cfg, dict):\n",
    "            return GNNConfig(**cfg)\n",
    "        if isinstance(cfg, (str, pathlib.Path)):\n",
    "            path = pathlib.Path(cfg)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                if path.suffix == \".json\":\n",
    "                    data = json.load(f)\n",
    "                elif path.suffix in {\".yml\", \".yaml\"} and yaml is not None:\n",
    "                    data = yaml.safe_load(f)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported file type for config path\")\n",
    "            return GNNConfig(**data)\n",
    "        raise TypeError(f\"Unsupported cfg type: {type(cfg)}\")\n",
    "\n",
    "    # pretty-print helper\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return asdict(self)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Core experiment wrapper\n",
    "# ----------------------------------------------------------------------\n",
    "class GNNExperiment:\n",
    "    \"\"\"\n",
    "    End-to-end wrapper around:\n",
    "       raw node/edge time-series  →  PyG snapshots  →  loaders  →  model\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------ constructor -------------------------------------------------\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_frames: Dict[str, pd.DataFrame],\n",
    "        edge_frames: Dict[str, pd.DataFrame],\n",
    "        graph: nx.DiGraph,\n",
    "        cfg: Union[GNNConfig, str, Dict[str, Any]] = GNNConfig(),\n",
    "    ):\n",
    "        # raw inputs\n",
    "        self.node_frames = node_frames     # {\"Tokyo\": df, ...}\n",
    "        self.edge_frames = edge_frames     # {\"tokyo-chubu\": df, ...}\n",
    "        self.graph       = graph\n",
    "\n",
    "        # config\n",
    "        self.cfg: GNNConfig = GNNConfig.load(cfg)\n",
    "\n",
    "        # runtime placeholders\n",
    "        self.reg_order:  List[str]     = []   # alphabetical node order\n",
    "        self.edge_order: List[tuple]   = []   # (src_idx, dst_idx)\n",
    "        self.snapshots   = None               # list[Data]\n",
    "\n",
    "        self.train_dl = self.val_dl = self.test_dl = None\n",
    "\n",
    "        self.model = None\n",
    "        self.optimizer = None\n",
    "        self.loss_fn = None\n",
    "        self.history: Dict[str, list] = {}\n",
    "\n",
    "        # device handling\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if (self.cfg.device == \"cuda\" and torch.cuda.is_available()) else \"cpu\"\n",
    "        )\n",
    "\n",
    "    # =========================== helpers =====================================\n",
    "    @staticmethod\n",
    "    def _edge_key(src: str, dst: str) -> str:\n",
    "        \"\"\"Convert (src, dst) into canonical 'src-dst' lowercase key.\"\"\"\n",
    "        return f\"{src}-{dst}\".lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def _ensure_same_index(idxs: List[pd.DatetimeIndex]) -> List[pd.Timestamp]:\n",
    "        \"\"\"Return sorted intersection of all DatetimeIndex objects.\"\"\"\n",
    "        common = sorted(set.intersection(*(set(i) for i in idxs)))\n",
    "        if not common:\n",
    "            raise ValueError(\"No common timestamps across supplied DataFrames\")\n",
    "        return common\n",
    "\n",
    "    # =================== 1. snapshot creation ================================\n",
    "    def prepare_snapshots(self) -> \"GNNExperiment\":\n",
    "        \"\"\"\n",
    "        Build `torch_geometric.data.Data` objects for each shared timestamp.\n",
    "        Stores them in `self.snapshots` and returns self.\n",
    "        \"\"\"\n",
    "        # --- deterministic node order ----------------------------------------\n",
    "        self.reg_order = sorted(self.graph.nodes)\n",
    "        node_pos = {n: i for i, n in enumerate(self.reg_order)}\n",
    "\n",
    "        # --- deterministic edge order ----------------------------------------\n",
    "        self.edge_order = [(node_pos[src], node_pos[dst])\n",
    "                           for (src, dst) in self.graph.edges]\n",
    "\n",
    "        # --- intersect timestamps --------------------------------------------\n",
    "        node_idxs = [df.index for df in self.node_frames.values()]\n",
    "        edge_idxs = [df.index for df in self.edge_frames.values()]\n",
    "        ts_common = self._ensure_same_index(node_idxs + edge_idxs)\n",
    "\n",
    "        # --- construct snapshot objects --------------------------------------\n",
    "        snapshots: List[Data] = []\n",
    "        for ts in ts_common:\n",
    "            # ---- node matrix & targets\n",
    "            feats, tgts = [], []\n",
    "            for region in self.reg_order:\n",
    "                row = self.node_frames[region].loc[ts]\n",
    "                tgts.append(row[self.cfg.target_col])\n",
    "                feats.append(row.drop(self.cfg.target_col).to_numpy(dtype=np.float32))\n",
    "            x = torch.tensor(np.vstack(feats), dtype=torch.float32)\n",
    "            y = torch.tensor(tgts, dtype=torch.float32)\n",
    "\n",
    "            # ---- edge attribute matrix\n",
    "            edge_rows = []\n",
    "            for src_idx, dst_idx in self.edge_order:\n",
    "                src_name, dst_name = self.reg_order[src_idx], self.reg_order[dst_idx]\n",
    "                key = self._edge_key(src_name, dst_name)\n",
    "                row = self.edge_frames[key].loc[ts]\n",
    "                edge_rows.append(row.to_numpy(dtype=np.float32))\n",
    "            edge_attr = torch.tensor(np.vstack(edge_rows), dtype=torch.float32)\n",
    "\n",
    "            # ---- edge index tensor (shape [2, E])\n",
    "            edge_index = torch.tensor(np.vstack(self.edge_order), dtype=torch.long)\n",
    "\n",
    "            snapshots.append(\n",
    "                Data(\n",
    "                    x=x,\n",
    "                    edge_index=edge_index,\n",
    "                    edge_attr=edge_attr,\n",
    "                    y=y,\n",
    "                    snap_time=torch.tensor([pd.Timestamp(ts).value]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.snapshots = snapshots\n",
    "        return self\n",
    "\n",
    "    # =================== 2. build loaders ====================================\n",
    "    def build_loaders(self) -> \"GNNExperiment\":\n",
    "        \"\"\"\n",
    "        Create `train_dl`, `val_dl`, `test_dl` according to `self.cfg`.\n",
    "        Must be called **after** `prepare_snapshots`.\n",
    "        \"\"\"\n",
    "        if self.snapshots is None:\n",
    "            raise RuntimeError(\"Call prepare_snapshots() before build_loaders()\")\n",
    "\n",
    "        # ---- chronological sort (snap_time is 1-elem tensor) -----------------\n",
    "        snaps_sorted = sorted(self.snapshots, key=lambda g: g.snap_time.item())\n",
    "\n",
    "        if self.cfg.split_mode == \"date\":\n",
    "            if self.cfg.cutoff_date is None:\n",
    "                raise ValueError(\"`cutoff_date` must be set in cfg for date split\")\n",
    "\n",
    "            cutoff_int = pd.Timestamp(self.cfg.cutoff_date).value\n",
    "            train_set = [g for g in snaps_sorted if g.snap_time.item() <= cutoff_int]\n",
    "            holdout   = [g for g in snaps_sorted if g.snap_time.item() >  cutoff_int]\n",
    "\n",
    "            if not holdout:\n",
    "                raise ValueError(\"No snapshots after cutoff_date for val/test split\")\n",
    "\n",
    "            # simple 50-50 val/test split on holdout\n",
    "            mid = len(holdout) // 2\n",
    "            val_set, test_set = holdout[:mid], holdout[mid:]\n",
    "\n",
    "        elif self.cfg.split_mode == \"ratio\":\n",
    "            n_total = len(snaps_sorted)\n",
    "            n_test  = int(n_total * self.cfg.test_ratio)\n",
    "            n_val   = int(n_total * self.cfg.val_ratio)\n",
    "            n_train = n_total - n_val - n_test\n",
    "\n",
    "            train_set = snaps_sorted[:n_train]\n",
    "            val_set   = snaps_sorted[n_train:n_train + n_val]\n",
    "            test_set  = snaps_sorted[n_train + n_val:]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown split_mode '{self.cfg.split_mode}'\")\n",
    "\n",
    "        # ---- DataLoaders ------------------------------------------------------\n",
    "        self.train_dl = DataLoader(\n",
    "            train_set,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            shuffle=self.cfg.shuffle_in_split,\n",
    "        )\n",
    "        self.val_dl = DataLoader(\n",
    "            val_set,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        self.test_dl = DataLoader(\n",
    "            test_set,\n",
    "            batch_size=self.cfg.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    # =================== placeholders for later ==============================\n",
    "    def init_model(self) -> \"GNNExperiment\":\n",
    "        \"\"\"Instantiate the requested GNN backbone + head (TODO).\"\"\"\n",
    "        # TODO\n",
    "        return self\n",
    "\n",
    "    def compile(self) -> \"GNNExperiment\":\n",
    "        \"\"\"Attach loss fn, optimiser, schedulers, etc. (TODO).\"\"\"\n",
    "        # TODO\n",
    "        return self\n",
    "\n",
    "    def train(self, debug: bool = False):\n",
    "        \"\"\"Main training loop (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, split: str = \"val\") -> Dict[str, float]:\n",
    "        \"\"\"Evaluate on a chosen split (TODO).\"\"\"\n",
    "        # TODO\n",
    "        return {}\n",
    "\n",
    "    def predict(self, node_frames_new, edge_frames_new, timestamps):\n",
    "        \"\"\"Predict on unseen timestamps (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def plot_history(self, metric: str = \"loss\"):\n",
    "        \"\"\"Matplotlib learning-curve plot (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def save(self, run_dir: Union[str, pathlib.Path]):\n",
    "        \"\"\"Save config, weights, scaler, etc. (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, run_dir: Union[str, pathlib.Path]) -> \"GNNExperiment\":\n",
    "        \"\"\"Reload a previously saved experiment (TODO).\"\"\"\n",
    "        # TODO\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
