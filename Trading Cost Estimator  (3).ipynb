{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e612e3e3",
   "metadata": {},
   "source": [
    "## Trading costs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066019eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trading-cost / marginal-price & elasticity helpers\n",
    "==================================================\n",
    "\n",
    "Public API\n",
    "----------\n",
    "trading_cost(slice_df, vol_mwh, side)            -> total_¥ , clearing_price\n",
    "marginal_price(slice_df, extra_vol_mwh, side)    -> incr_¥ , incr_¥/kWh , Δprice\n",
    "trading_cost_series(container, vol_mwh, side)    -> DataFrame per timeslot\n",
    "marginal_price_series(container, extra_vol_mwh)  -> DataFrame per timeslot\n",
    "elasticity(slice_df, side)                       -> dV/dP Series or DataFrame\n",
    "elasticity_panel(container, side)                -> time × price grid(s)\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Literal, Union\n",
    "\n",
    "from jp_da_imb.trading_costs.bid_curve_struc import BidCurve, MultiBidCurve\n",
    "from jp_da_imb.trading_costs.bid_curve_stats import (\n",
    "    clearing_price,\n",
    "    clearing_demand,\n",
    "    _clearing_price_volume,      # internal helper from stats module\n",
    "    _iter_slices,                # internal helper from stats module\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1)  total cost to buy / sell 'vol_mwh'  (uniform-price auction)\n",
    "# ---------------------------------------------------------------------\n",
    "def trading_cost(\n",
    "    slice_df: pd.DataFrame,\n",
    "    vol_mwh: float,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Return (total ¥, clearing_price ¥/kWh) for the extra tranche.\"\"\"\n",
    "    if vol_mwh <= 0:\n",
    "        raise ValueError(\"vol_mwh must be positive\")\n",
    "\n",
    "    price = slice_df.index.to_numpy(dtype=float)\n",
    "\n",
    "    if side == \"buy\":\n",
    "        cum = slice_df[\"supply_cum\"].to_numpy(dtype=float)\n",
    "        cp = np.interp(vol_mwh, cum, price)\n",
    "    elif side == \"sell\":\n",
    "        # Demand curve runs from high-price to low-price\n",
    "        price_rev = price[::-1]\n",
    "        cum_rev   = slice_df[\"demand_cum\"].to_numpy(dtype=float)[::-1]\n",
    "        cp = np.interp(vol_mwh, cum_rev, price_rev)\n",
    "    else:\n",
    "        raise ValueError(\"side must be 'buy' or 'sell'\")\n",
    "\n",
    "    total = vol_mwh * cp * 1_000          # ¥/kWh × MWh\n",
    "    return float(total), float(cp)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2)  marginal price impact of an *extra* volume tranche\n",
    "# ---------------------------------------------------------------------\n",
    "def marginal_price(\n",
    "    slice_df: pd.DataFrame,\n",
    "    extra_vol_mwh: float = 0.5,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Incremental cost ¥, marginal price ¥/kWh and Δprice ¥/kWh beyond clearing.\n",
    "\n",
    "    • Adds *extra_vol_mwh* to demand (buy) or supply (sell) cum-curve,\n",
    "      recomputes clearing, and returns:\n",
    "        (incremental_cost_¥ , marginal_price_¥/kWh , |Δclearing_price|)\n",
    "    \"\"\"\n",
    "    if extra_vol_mwh <= 0:\n",
    "        raise ValueError(\"extra_vol_mwh must be positive\")\n",
    "\n",
    "    # original clearing\n",
    "    cv0 = clearing_demand(slice_df)\n",
    "    cp0 = clearing_price(slice_df)\n",
    "\n",
    "    # shift curve\n",
    "    adj = slice_df.copy()\n",
    "    if side == \"buy\":\n",
    "        adj[\"demand_cum\"] += extra_vol_mwh\n",
    "    elif side == \"sell\":\n",
    "        adj[\"supply_cum\"] += extra_vol_mwh\n",
    "\n",
    "    # new clearing\n",
    "    cv1 = clearing_demand(adj)\n",
    "    cp1 = clearing_price(adj)\n",
    "\n",
    "    incr_cost  = (cv1 + 0.0) * cp1 * 1_000 - cv0 * cp0 * 1_000\n",
    "    incr_price = incr_cost / (extra_vol_mwh * 1_000)\n",
    "\n",
    "    return float(incr_cost), float(incr_price), abs(cp1 - cp0)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3)  vectorised helpers  (work with BidCurve or MultiBidCurve)\n",
    "# ---------------------------------------------------------------------\n",
    "def trading_cost_series(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    vol_mwh: float,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"DataFrame with columns ['total_cost','clearing_price'] for every slot.\"\"\"\n",
    "    labels, costs, cps = [], [], []\n",
    "    for lbl, sl in _iter_slices(container):\n",
    "        c, p = trading_cost(sl, vol_mwh, side=side)\n",
    "        labels.append(lbl); costs.append(c); cps.append(p)\n",
    "\n",
    "    idx_name = \"timestamp\" if isinstance(container, MultiBidCurve) else \"time_code\"\n",
    "    return pd.DataFrame(\n",
    "        {\"total_cost\": costs, \"clearing_price\": cps},\n",
    "        index=pd.Index(labels, name=idx_name)\n",
    "    )\n",
    "\n",
    "\n",
    "def marginal_price_series(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    extra_vol_mwh: float = 0.5,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"DataFrame with ['incremental_cost','marginal_price'] per timeslot.\"\"\"\n",
    "    labels, inc_c, inc_p = [], [], []\n",
    "    for lbl, sl in _iter_slices(container):\n",
    "        c, p, _ = marginal_price(sl, extra_vol_mwh=extra_vol_mwh, side=side)\n",
    "        labels.append(lbl); inc_c.append(c); inc_p.append(p)\n",
    "\n",
    "    idx_name = \"timestamp\" if isinstance(container, MultiBidCurve) else \"time_code\"\n",
    "    return pd.DataFrame(\n",
    "        {\"incremental_cost\": inc_c, \"marginal_price\": inc_p},\n",
    "        index=pd.Index(labels, name=idx_name)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot helpers for supply–demand curves and trading-cost metrics.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Literal, Union\n",
    "\n",
    "from jp_da_imb.trading_costs.bid_curve_struc import BidCurve, MultiBidCurve\n",
    "from jp_da_imb.trading_costs.trading_cost_estimation import (\n",
    "    trading_cost_series, marginal_price_series\n",
    ")\n",
    "from jp_da_imb.trading_costs.bid_curve_stats import timeslot_summary\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "def _get_slice(container, ts):\n",
    "    if isinstance(container, MultiBidCurve):\n",
    "        return container[ts]\n",
    "    if isinstance(container, BidCurve):\n",
    "        if isinstance(ts, int):\n",
    "            return container.slice_time(ts)\n",
    "        raise TypeError(\"BidCurve expects time_code 1–48 (int)\")\n",
    "    raise TypeError(\"container must be BidCurve or MultiBidCurve\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) supply & demand curve for a single timestamp\n",
    "# -------------------------------------------------------------------\n",
    "def plot_supply_demand(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    ts: Union[str, pd.Timestamp, int],\n",
    "    *,\n",
    "    ylim: float | None = None,\n",
    "    xlow: float | None = None,\n",
    "    xhigh: float | None = None,\n",
    "):\n",
    "    curve = _get_slice(container, ts)\n",
    "    px  = curve.index.to_numpy(dtype=float)\n",
    "    sup = curve[\"supply_cum\"].to_numpy(dtype=float)\n",
    "    dem = curve[\"demand_cum\"].to_numpy(dtype=float)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.step(px, sup, where=\"post\", label=\"Supply (cum)\", linewidth=1.2)\n",
    "    ax.step(px, dem, where=\"post\", label=\"Demand (cum)\", linewidth=1.2)\n",
    "    ax.set_xlabel(\"Price [¥/kWh]\")\n",
    "    ax.set_ylabel(\"Cumulative volume [MWh]\")\n",
    "    ax.set_title(f\"JEPX supply & demand curves — {ts}\")\n",
    "    if ylim:  ax.set_ylim(bottom=0, top=ylim)\n",
    "    if xlow or xhigh: ax.set_xlim(xlow, xhigh)\n",
    "    ax.legend()\n",
    "    ax.grid(True, which=\"both\", alpha=0.3)\n",
    "    return fig\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) trading-cost series  (uniform clearing price)\n",
    "# -------------------------------------------------------------------\n",
    "def plot_trading_cost_series(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    vol_mwh: float,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    "    metric: Literal[\"total_cost\", \"clearing_price\"] = \"total_cost\",\n",
    "):\n",
    "    df = trading_cost_series(container, vol_mwh, side=side)\n",
    "    if metric not in df.columns:\n",
    "        raise ValueError(f\"metric must be one of {list(df.columns)}\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df.index, df[metric], linewidth=1.2)\n",
    "    ax.set_xlabel(\"Time\" if isinstance(container, MultiBidCurve) else \"Time code (1-48)\")\n",
    "    ylabel = \"Total cost [¥]\" if metric == \"total_cost\" else \"Price [¥/kWh]\"\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(f\"{metric.replace('_',' ').title()} — {side.upper()} {vol_mwh} MWh each slot\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return fig\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) any metric from timeslot_summary()\n",
    "# -------------------------------------------------------------------\n",
    "def plot_metric_series(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    metric: Literal[\n",
    "        \"clearing_price\", \"clearing_volume\",\n",
    "        \"vwap\", \"price_min\", \"price_max\", \"imbalance_integral\"\n",
    "    ] = \"clearing_price\",\n",
    "    *,\n",
    "    vwap_side: str = \"supply\",\n",
    "):\n",
    "    summary = timeslot_summary(container, vwap_side=vwap_side)\n",
    "    if metric not in summary.columns:\n",
    "        raise ValueError(f\"metric must be one of {list(summary.columns)}\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(summary.index, summary[metric], linewidth=1.2)\n",
    "    ax.set_xlabel(\"Time\" if isinstance(container, MultiBidCurve) else \"Time code (1-48)\")\n",
    "    ax.set_ylabel(metric.replace(\"_\", \" \").title())\n",
    "    ax.set_title(f\"{metric.replace('_', ' ').title()} per timeslot\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# helper – iterate over every 30-min slice in a container\n",
    "# ------------------------------------------------------------\n",
    "def _iter_slices(container: Union[BidCurve, MultiBidCurve]):\n",
    "    \"\"\"\n",
    "    Yield (label, slice_df) pairs where *label* is:\n",
    "      • time_code 1-48            for BidCurve\n",
    "      • pd.Timestamp              for MultiBidCurve\n",
    "    \"\"\"\n",
    "    if isinstance(container, BidCurve):\n",
    "        for tc in range(1, 49):\n",
    "            yield tc, container.slice_time(tc)\n",
    "\n",
    "    elif isinstance(container, MultiBidCurve):\n",
    "        for ts in container:\n",
    "            yield ts, container[ts]      # indexing sugar we added\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"Expected BidCurve or MultiBidCurve\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# clearing-series  (price & volume for **all** slices)\n",
    "# ------------------------------------------------------------\n",
    "def clearing_series(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    *,\n",
    "    return_dataframe: bool = True\n",
    ") -> Union[pd.DataFrame, Tuple[pd.Series, pd.Series]]:\n",
    "    \"\"\"\n",
    "    Vectorised clearing stats for *all* slices in the container.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    • DataFrame (default) with columns ['clearing_price', 'clearing_volume']\n",
    "      and index = time_code 1-48 | timestamps\n",
    "    • Or (price_series, volume_series) if `return_dataframe=False`\n",
    "    \"\"\"\n",
    "    labels, prices, vols = [], [], []\n",
    "\n",
    "    for lbl, curve_slice in _iter_slices(container):\n",
    "        cp, cv = clearing_price_volume(curve_slice)\n",
    "        labels.append(lbl)\n",
    "        prices.append(cp)\n",
    "        vols.append(cv)\n",
    "\n",
    "    price_s = pd.Series(prices, index=labels, name=\"clearing_price\")\n",
    "    vol_s   = pd.Series(vols,   index=labels, name=\"clearing_volume\")\n",
    "\n",
    "    if return_dataframe:\n",
    "        return pd.concat([price_s, vol_s], axis=1)\n",
    "\n",
    "    return price_s, vol_s\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# residual volume  (supply or demand beyond a price threshold)\n",
    "# ------------------------------------------------------------\n",
    "def residual_volume(\n",
    "    slice_df: pd.DataFrame,\n",
    "    price_threshold: float,\n",
    "    side: str = \"supply\"\n",
    ") -> float:\n",
    "\n",
    "    price = slice_df.index.to_numpy(dtype=float)\n",
    "\n",
    "    if side == \"supply\":\n",
    "        sup   = slice_df[\"supply_cum\"].to_numpy(dtype=float)\n",
    "        total = sup[-1]\n",
    "        filled = np.interp(price_threshold, price, sup)\n",
    "        return float(total - filled)\n",
    "\n",
    "    if side == \"demand\":\n",
    "        dem    = slice_df[\"demand_cum\"].to_numpy(dtype=float)\n",
    "        filled = np.interp(price_threshold, price, dem)\n",
    "        return float(filled)\n",
    "\n",
    "    raise ValueError(\"side must be 'supply' or 'demand'\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# imbalance  (supply minus demand; area if integrated=True)\n",
    "# ------------------------------------------------------------\n",
    "def imbalance(\n",
    "    slice_df: pd.DataFrame,\n",
    "    *,\n",
    "    integrated: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Supply-minus-demand difference for each price bin.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    • pd.Series if integrated=False\n",
    "    • scalar     if integrated=True\n",
    "    \"\"\"\n",
    "    diff = slice_df[\"supply_cum\"] - slice_df[\"demand_cum\"]\n",
    "\n",
    "    if integrated:\n",
    "        price = slice_df.index.to_numpy(dtype=float)\n",
    "        return float(np.trapz(diff, price))\n",
    "\n",
    "    return diff\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "# BidCurve   – one day (48 rows)\n",
    "# ==================================================================\n",
    "@dataclass\n",
    "class BidCurve:\n",
    "    region: str\n",
    "    date:   pd.Timestamp\n",
    "    bins:   np.ndarray\n",
    "    supply: pd.DataFrame          # 48 × N_bins\n",
    "    demand: pd.DataFrame\n",
    "    df_raw: pd.DataFrame\n",
    "    _long_cache: pd.DataFrame | None = field(default=None, init=False, repr=False)\n",
    "\n",
    "    def slice_time(self, time_code: int) -> pd.DataFrame:\n",
    "        \"\"\"Return (price_bin × 2) DataFrame for a 30-min slot.\"\"\"\n",
    "        if not (1 <= time_code <= 48):\n",
    "            raise ValueError(\"time_code must be 1-48\")\n",
    "        row = time_code - 1\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"supply_cum\":  self.supply.iloc[row].values,\n",
    "                \"demand_cum\":  self.demand.iloc[row].values,\n",
    "            },\n",
    "            index=self.bins,\n",
    "        )\n",
    "\n",
    "    def to_long(self) -> pd.DataFrame:\n",
    "        if self._long_cache is not None:\n",
    "            return self._long_cache\n",
    "\n",
    "        df_sup = (\n",
    "            self.supply.assign(side=\"supply\")\n",
    "            .stack().rename(\"cum_vol\")\n",
    "            .reset_index(names=[\"time_code\", \"price\"])\n",
    "        )\n",
    "        df_dem = (\n",
    "            self.demand.assign(side=\"demand\")\n",
    "            .stack().rename(\"cum_vol\")\n",
    "            .reset_index(names=[\"time_code\", \"price\"])\n",
    "        )\n",
    "        long = pd.concat([df_sup, df_dem])\n",
    "        long[\"date\"]    = self.date\n",
    "        long[\"region\"]  = self.region\n",
    "        self._long_cache = long[[\"date\", \"region\", \"time_code\", \"side\", \"price\", \"cum_vol\"]]\n",
    "        return self._long_cache\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<BidCurve {self.region} {self.date.date()} (48 × {len(self.bins)} bins)>\"\n",
    "\n",
    "\n",
    "# ==================================================================\n",
    "# MultiBidCurve   – many days, 30-min timestamps\n",
    "# ==================================================================\n",
    "@dataclass\n",
    "class MultiBidCurve:\n",
    "    region: str\n",
    "    bins:   np.ndarray\n",
    "    supply: pd.DataFrame          # index = timestamp, columns = bins\n",
    "    demand: pd.DataFrame\n",
    "    df_raw: pd.DataFrame\n",
    "    _long_cache: pd.DataFrame | None = field(default=None, init=False, repr=False)\n",
    "\n",
    "    @property\n",
    "    def dates(self) -> pd.DatetimeIndex:\n",
    "        return self.supply.index.normalize().unique()\n",
    "\n",
    "    def slice_time(self, ts: Union[str, pd.Timestamp]) -> pd.DataFrame:\n",
    "        ts = pd.to_datetime(ts)\n",
    "        row_sup = self.supply.loc[ts]\n",
    "        row_dem = self.demand.loc[ts]\n",
    "        return pd.DataFrame(\n",
    "            {\"supply_cum\": row_sup.values, \"demand_cum\": row_dem.values},\n",
    "            index=self.bins,\n",
    "        )\n",
    "\n",
    "    def slice_day(self, date: Union[str, pd.Timestamp]) -> BidCurve:\n",
    "        d = pd.to_datetime(date).normalize()\n",
    "        mask = self.supply.index.normalize() == d\n",
    "        if mask.sum() != 48:\n",
    "            raise ValueError(f\"Expected 48 rows for {d.date()}, got {mask.sum()}\")\n",
    "        sup_day = self.supply.loc[mask].reset_index(drop=True)\n",
    "        dem_day = self.demand.loc[mask].reset_index(drop=True)\n",
    "        return BidCurve(\n",
    "            region=self.region,\n",
    "            date=d,\n",
    "            bins=self.bins,\n",
    "            supply=sup_day,\n",
    "            demand=dem_day,\n",
    "            df_raw=self.df_raw.loc[mask].reset_index(drop=True),\n",
    "        )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# timeslot_summary  (per-slot diagnostics table)\n",
    "# ------------------------------------------------------------\n",
    "def timeslot_summary(\n",
    "    container: Union[BidCurve, MultiBidCurve],\n",
    "    vwap_side: str = \"supply\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Columns:\n",
    "      clearing_price, clearing_volume, vwap,\n",
    "      price_min, price_max, imbalance_integral\n",
    "    \"\"\"\n",
    "    if vwap_side not in {\"supply\", \"demand\"}:\n",
    "        raise ValueError(\"vwap_side must be 'supply' or 'demand'\")\n",
    "\n",
    "    labels, cp, cv, vwap, pmin, pmax, imb = [], [], [], [], [], [], []\n",
    "\n",
    "    for lbl, sl in _iter_slices(container):\n",
    "        _cp, _cv = clearing_price_volume(sl)\n",
    "        cp.append(_cp); cv.append(_cv)\n",
    "\n",
    "        price   = sl.index.to_numpy(dtype=float)\n",
    "        cum_vol = sl[f\"{vwap_side}_cum\"].to_numpy(dtype=float)\n",
    "        inc_vol = np.diff(np.concatenate(([0.0], cum_vol)))\n",
    "        tot_vol = cum_vol[-1]\n",
    "        vwap.append((price * inc_vol).sum() / tot_vol if tot_vol > 0 else np.nan)\n",
    "\n",
    "        nz = np.flatnonzero(inc_vol)\n",
    "        pmin.append(price[nz[0]]  if nz.size else np.nan)\n",
    "        pmax.append(price[nz[-1]] if nz.size else np.nan)\n",
    "\n",
    "        imb.append(imbalance(sl, integrated=True))\n",
    "        labels.append(lbl)\n",
    "\n",
    "    idx_name = \"timestamp\" if isinstance(container, MultiBidCurve) else \"time_code\"\n",
    "    summary = pd.DataFrame(\n",
    "        {\n",
    "            \"clearing_price\":      cp,\n",
    "            \"clearing_volume\":     cv,\n",
    "            \"vwap\":                vwap,\n",
    "            \"price_min\":           pmin,\n",
    "            \"price_max\":           pmax,\n",
    "            \"imbalance_integral\":  imb,\n",
    "        },\n",
    "        index=pd.Index(labels, name=idx_name),\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# alt_loader.py  ·  extra helpers + row-wise loader\n",
    "# ---------------------------------------------------------------------\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Mapping, Iterable, Dict, Union, Literal\n",
    "\n",
    "from jp_da_imb.trading_costs.bid_curve_struc import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "# add functionality to load different types of data -------------------\n",
    "def _read_any(path, **kw) -> pd.DataFrame:\n",
    "    \"\"\"Try Parquet first (you can extend to CSV/XLSX if needed).\"\"\"\n",
    "    return pd.read_parquet(path, **kw)\n",
    "\n",
    "\n",
    "def _make_price_grid(\n",
    "    df: pd.DataFrame,\n",
    "    price_step: float,\n",
    "    pad: float = 0.0,\n",
    "    price_col: str = \"price\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Common ascending grid so that every slice shares the same bins.\n",
    "    \"\"\"\n",
    "    pmin, pmax = df[price_col].min() - pad, df[price_col].max() + pad\n",
    "    # round to exact step to avoid FP jitter\n",
    "    pmin = math.floor(pmin / price_step) * price_step\n",
    "    pmax = math.ceil( pmax / price_step) * price_step\n",
    "    n    = int((pmax - pmin) / price_step) + 1\n",
    "    return np.round(np.linspace(pmin, pmax, n), decimals=6)   # 6-dp safety\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "def _build_slice(\n",
    "    rows: pd.DataFrame,\n",
    "    price_bins: np.ndarray\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build supply_cum & demand_cum arrays (len = len(price_bins))\n",
    "    *rows* contains all buy/sell entries for **one timestamp**.\n",
    "    \"\"\"\n",
    "    sup = np.zeros(len(price_bins), dtype=float)   # supply cum\n",
    "    dem = np.zeros(len(price_bins), dtype=float)   # demand cum\n",
    "\n",
    "    # split rows --------------------------------------------------------\n",
    "    sell_rows = rows[rows[\"order\"] == \"sell\"].sort_values(\"price\")\n",
    "    buy_rows  = rows[rows[\"order\"] == \"buy\"].sort_values(\"price\", ascending=False)\n",
    "\n",
    "    # ---- fill supply (monotone ↑ with price) -------------------------\n",
    "    for _, r in sell_rows.iterrows():\n",
    "        idx = np.searchsorted(price_bins, r[\"price\"], side=\"left\")\n",
    "        sup[idx:] = r[\"volume\"]\n",
    "\n",
    "    # ---- fill demand (monotone ↓ with price) -------------------------\n",
    "    for _, r in buy_rows.iterrows():\n",
    "        idx = np.searchsorted(price_bins, r[\"price\"], side=\"left\")\n",
    "        dem[: idx + 1] = r[\"volume\"]\n",
    "\n",
    "    return sup, dem\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "def load_curves_rows(\n",
    "    path: str | Path,\n",
    "    *,\n",
    "    area: str,\n",
    "    price_step: float  = 0.01,\n",
    "    tz: str           = \"Asia/Tokyo\",\n",
    "    vol_col: str      = \"volume\",\n",
    "    price_col: str    = \"price\",\n",
    "    order_col: str    = \"order\",\n",
    "    area_col: str     = \"area\",\n",
    "    dt_col: str       = \"dt\",\n",
    "    **read_kw,\n",
    ") -> MultiBidCurve:\n",
    "    \"\"\"\n",
    "    Read the *row-wise* file and return a **MultiBidCurve** for *area*.\n",
    "\n",
    "    * Every unique timestamp becomes one 30-minute curve slice.\n",
    "    * One common price grid (min-max in data, `price_step` increments).\n",
    "    \"\"\"\n",
    "    df = _read_any(path, **read_kw).copy()\n",
    "\n",
    "    req = {vol_col, price_col, order_col, area_col, dt_col}\n",
    "    if not req.issubset(df.columns):\n",
    "        raise ValueError(f\"File missing columns: {req - set(df.columns)}\")\n",
    "\n",
    "    # filter region ----------------------------------------------------\n",
    "    df = df[df[area_col] == area]\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No rows found for area '{area}'\")\n",
    "\n",
    "    # tidy types -------------------------------------------------------\n",
    "    df[vol_col]   = df[vol_col].astype(float)\n",
    "    df[price_col] = df[price_col].astype(float)\n",
    "    df[order_col] = df[order_col].str.lower().str.strip()\n",
    "    df[dt_col]    = pd.to_datetime(df[dt_col]).dt.tz_convert(tz)\n",
    "\n",
    "    # common price grid ------------------------------------------------\n",
    "    bins = _make_price_grid(df[[price_col]], price_step, price_col=price_col)\n",
    "\n",
    "    # pre-allocate containers -----------------------------------------\n",
    "    ts_index = sorted(df[dt_col].unique())\n",
    "    sup_mat  = np.zeros((len(ts_index), len(bins)), dtype=float)\n",
    "    dem_mat  = np.zeros_like(sup_mat)\n",
    "\n",
    "    # build each slice -------------------------------------------------\n",
    "    for i, ts in enumerate(ts_index):\n",
    "        rows = df.loc[df[dt_col] == ts, [vol_col, price_col, order_col]]\n",
    "        sup, dem = _build_slice(\n",
    "            rows.rename(columns={vol_col: \"volume\",\n",
    "                                 price_col: \"price\",\n",
    "                                 order_col: \"order\"}),\n",
    "            bins,\n",
    "        )\n",
    "        sup_mat[i, :] = sup\n",
    "        dem_mat[i, :] = dem\n",
    "\n",
    "    # wrap into DataFrames with proper index/columns -------------------\n",
    "    sup_df = pd.DataFrame(sup_mat, index=ts_index, columns=bins)\n",
    "    dem_df = pd.DataFrame(dem_mat, index=ts_index, columns=bins)\n",
    "\n",
    "    return MultiBidCurve(\n",
    "        region = area,\n",
    "        bins   = bins,\n",
    "        supply = sup_df,\n",
    "        demand = dem_df,\n",
    "        df_raw = df,           # keep original long rows\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ---------------------------------------------------------------\n",
    "    def to_long(self) -> pd.DataFrame:\n",
    "        long = pd.concat(\n",
    "            [_stack(self.supply, side=\"supply\"),\n",
    "             _stack(self.demand, side=\"demand\")]\n",
    "        )\n",
    "        long[\"region\"] = self.region\n",
    "        long[\"date\"]   = long[\"timestamp\"].dt.normalize()\n",
    "        long[\"time_code\"] = (\n",
    "            long[\"timestamp\"].dt.hour * 60 + long[\"timestamp\"].dt.minute\n",
    "        ) // 30 + 1\n",
    "        self._long_cache = long[\n",
    "            [\"date\", \"region\", \"time_code\", \"timestamp\", \"side\", \"price\", \"cum_vol\"]\n",
    "        ]\n",
    "        return self._long_cache\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    def __repr__(self):\n",
    "        n_days = len(self.dates)\n",
    "        return f\"<MultiBidCurve {self.region} [{n_days} days, {len(self.bins)} bins]>\"\n",
    "\n",
    "    # so you can iterate the new object -----------------------------\n",
    "    def __getitem__(self, ts: str | pd.Timestamp):\n",
    "        return self.slice_time(ts)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.supply.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198e743",
   "metadata": {},
   "source": [
    "| Module               | Function / Method                                            | What it does (one-liner)                                               |\n",
    "| -------------------- | ------------------------------------------------------------ | ---------------------------------------------------------------------- |\n",
    "| **`jepx_loader.py`** | **`load_curve(path, *, region, date)`**                      | Read a *single-day* 48-row file → `BidCurve`.                          |\n",
    "|                      | **`load_curves(path, *, region)`**                           | Read a *multi-day* file → `MultiBidCurve` (index = 30-min timestamps). |\n",
    "|                      | **`BidCurve.slice_time(tc)`**                                | Return supply & demand arrays for time-code 1-48.                      |\n",
    "|                      | **`BidCurve.to_long()`**                                     | Long “tidy” DataFrame (date, time\\_code, side, price, cum\\_vol).       |\n",
    "|                      | **`MultiBidCurve.__getitem__(ts)`**                          | Quick accessor: `panel['2025-07-08 12:00']` → curve slice.             |\n",
    "|                      | **`MultiBidCurve.slice_day(date)`**                          | Pop one day back out as a `BidCurve`.                                  |\n",
    "|                      | **`MultiBidCurve.to_long()`**                                | Long DF with timestamp granularity.                                    |\n",
    "|                      | **`MultiBidCurve.iter_timeslices()`**                        | Generator over every 30-min slice.                                     |\n",
    "| **`jepx_stats.py`**  | **`clearing_price(slice_df)`**                               | Intersection price (¥/kWh) for one slice.                              |\n",
    "|                      | **`clearing_demand / clearing_supply(slice_df)`**            | Cleared MWh on either side.                                            |\n",
    "|                      | **`residual_volume(slice_df, price, side)`**                 | Remaining MWh above a price threshold.                                 |\n",
    "|                      | **`imbalance(slice_df, integrated=False)`**                  | Supply-minus-demand vector or its integral.                            |\n",
    "|                      | **`trading_cost(slice_df, vol, side)`**                      | `total ¥`, `avg ¥/kWh` to buy/sell *vol* in one slice.                 |\n",
    "|                      | **`elasticity(slice_df, side)`**                             | dVolume/dPrice curve (slope) per price bin.                            |\n",
    "|                      | **`clearing_series(container)`**                             | Time-series of clearing price & volume for **all** slots.              |\n",
    "|                      | **`trading_cost_series(container, vol, side)`**              | Series/DataFrame of cost or avg price per slot.                        |\n",
    "|                      | **`elasticity_panel(container, side)`**                      | Time × price grid(s) of elasticity.                                    |\n",
    "|                      | **`timeslot_summary(container)`**                            | Table per slot: clearing P/V, VWAP, min/max price, imbalance.          |\n",
    "| **`jepx_plots.py`**  | **`plot_supply_demand(container, ts)`**                      | Step plot of supply & demand curves for one timestamp.                 |\n",
    "|                      | **`plot_trading_cost_series(container, vol, side, metric)`** | Line chart of total cost *or* avg price over time.                     |\n",
    "|                      | **`plot_metric_series(container, metric)`**                  | Generic plot for any column from `timeslot_summary()`.                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff64123",
   "metadata": {},
   "source": [
    "### NEW NEW NEW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jepx_stats.py  ───────────  point-price cost\n",
    "def trading_cost_at_price(slice_df, price, *, side=\"buy\"):\n",
    "    \"\"\"Cost (buy) or revenue (sell) if everything trades *at* that price.\"\"\"\n",
    "    price = float(price)\n",
    "    if side == \"buy\":\n",
    "        vol = np.interp(price, slice_df.index, slice_df[\"supply_cum\"])\n",
    "    elif side == \"sell\":\n",
    "        vol = np.interp(price, slice_df.index, slice_df[\"demand_cum\"])\n",
    "    else:\n",
    "        raise ValueError(\"side must be 'buy' or 'sell'\")\n",
    "    total = price * vol * 1_000             # ¥/kWh × MWh → ¥\n",
    "    return vol, total, price                # avg_price == price\n",
    "\n",
    "\n",
    "def trading_cost_at_price_series(container, price, *, side=\"buy\",\n",
    "                                 metric=\"total_cost\", return_dataframe=True):\n",
    "    labels, vols, totals = [], [], []\n",
    "    for lbl, sl in _iter_slices(container):\n",
    "        v, t, _ = trading_cost_at_price(sl, price, side=side)\n",
    "        labels.append(lbl); vols.append(v); totals.append(t)\n",
    "    vol_s   = pd.Series(vols,   index=labels, name=\"volume\")\n",
    "    tot_s   = pd.Series(totals, index=labels, name=\"total_cost\")\n",
    "    if not return_dataframe:\n",
    "        return {\"volume\": vol_s, \"total_cost\": tot_s}[metric]\n",
    "    return pd.concat([vol_s, tot_s], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c762e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Mariginal price correct form \n",
    "# jepx_stats.py  ───────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal, Tuple\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "# 1) One-slice marginal impact\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "def marginal_price_impact(\n",
    "    slice_df: pd.DataFrame,\n",
    "    qty_mwh: float,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Add **qty_mwh** to demand ('buy') or supply ('sell') and\n",
    "    return (old_cp, new_cp, extra_cost_approx).\n",
    "\n",
    "    extra_cost_approx = (new_cp - old_cp) × qty_mwh × 1 000   [¥]\n",
    "    \"\"\"\n",
    "    if qty_mwh <= 0:\n",
    "        raise ValueError(\"qty_mwh must be > 0\")\n",
    "\n",
    "    # ---------- original clearing -----------------------------------\n",
    "    old_cp, _ = _clearing_price_volume(slice_df)\n",
    "\n",
    "    # ---------- shift curve -----------------------------------------\n",
    "    adj = slice_df.copy()\n",
    "    if side == \"buy\":\n",
    "        adj[\"demand_cum\"] += qty_mwh\n",
    "    elif side == \"sell\":\n",
    "        adj[\"supply_cum\"] += qty_mwh\n",
    "    else:\n",
    "        raise ValueError(\"side must be 'buy' or 'sell'\")\n",
    "\n",
    "    new_cp, _ = _clearing_price_volume(adj)\n",
    "\n",
    "    delta_price = new_cp - old_cp                     # ¥/kWh\n",
    "    extra_cost  = delta_price * qty_mwh * 1_000       # ¥\n",
    "\n",
    "    return old_cp, new_cp, extra_cost\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "# 2) Vectorised over all timeslots\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "def marginal_price_impact_series(\n",
    "    container,\n",
    "    qty_mwh: float,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    "    metric: Literal[\"delta_price\", \"extra_cost\"] = \"delta_price\",\n",
    "    return_dataframe: bool = True,\n",
    "):\n",
    "    labels, dP, d¥ = [], [], []\n",
    "\n",
    "    for lbl, sl in _iter_slices(container):\n",
    "        cp0, cp1, extra = marginal_price_impact(sl, qty_mwh, side=side)\n",
    "        labels.append(lbl)\n",
    "        dP.append(cp1 - cp0)\n",
    "        d¥.append(extra)\n",
    "\n",
    "    idx_name = \"timestamp\" if hasattr(container, \"slice_day\") else \"time_code\"\n",
    "    dP_s = pd.Series(dP, index=labels, name=\"delta_price\")   # ¥/kWh\n",
    "    d¥_s = pd.Series(d¥, index=labels, name=\"extra_cost\")    # ¥\n",
    "\n",
    "    if not return_dataframe:\n",
    "        return {\"delta_price\": dP_s, \"extra_cost\": d¥_s}[metric]\n",
    "\n",
    "    return pd.concat([dP_s, d¥_s], axis=1).rename_axis(idx_name)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "# 3) Quick plot\n",
    "# ────────────────────────────────────────────────────────────────────\n",
    "def plot_marginal_price_impact(\n",
    "    container,\n",
    "    qty_mwh: float,\n",
    "    *,\n",
    "    side: Literal[\"buy\", \"sell\"] = \"buy\",\n",
    "    metric: Literal[\"delta_price\", \"extra_cost\"] = \"delta_price\",\n",
    "):\n",
    "    data = marginal_price_impact_series(\n",
    "        container, qty_mwh, side=side, return_dataframe=False, metric=metric\n",
    "    )\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(data.index, data.values, linewidth=1.2)\n",
    "    ax.set_xlabel(\"Time\" if hasattr(container, \"slice_day\") else \"Time code (1-48)\")\n",
    "    if metric == \"delta_price\":\n",
    "        ax.set_ylabel(\"ΔPrice [¥/kWh]\")\n",
    "        title_y = \"Price impact\"\n",
    "    else:\n",
    "        ax.set_ylabel(\"Extra cost [¥]\")\n",
    "        title_y = \"Extra ¥ out-of-pocket\"\n",
    "    ax.set_title(f\"{title_y} | +{qty_mwh} MWh {side.upper()} per slot\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af589843",
   "metadata": {},
   "source": [
    "### Combining regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from jp_da_imb.trading_costs.alt_loader import load_curves_rows\n",
    "from jp_da_imb.trading_costs.bid_curve_struc import MultiBidCurve\n",
    "\n",
    "\n",
    "def _sum_rows(df_list):\n",
    "    \"\"\"fast element-wise sum of DataFrames that share index/columns\"\"\"\n",
    "    return sum(df_list)\n",
    "\n",
    "\n",
    "def _aggregate_slice(\n",
    "    panels: List[MultiBidCurve],\n",
    "    ts,\n",
    "    price_bins: np.ndarray,\n",
    "    join_char: str = \"-\"\n",
    ") -> List[Tuple[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    For one timestamp, merge panels that share the same group-ID.\n",
    "    Returns list of (name, slice_df).\n",
    "    \"\"\"\n",
    "    by_gid: Dict[int, List[MultiBidCurve]] = {}\n",
    "    for p in panels:\n",
    "        gid = p.groups.get(ts, pd.NA)\n",
    "        if pd.isna(gid):\n",
    "            continue\n",
    "        by_gid.setdefault(int(gid), []).append(p)\n",
    "\n",
    "    out = []\n",
    "    for gid, plist in by_gid.items():\n",
    "        sup_vec = _sum_rows([p.supply.loc[ts] for p in plist])\n",
    "        dem_vec = _sum_rows([p.demand.loc[ts] for p in plist])\n",
    "\n",
    "        name = join_char.join(sorted(p.region for p in plist))\n",
    "        slice_df = pd.DataFrame(\n",
    "            {\n",
    "                \"supply_cum\": sup_vec.values,\n",
    "                \"demand_cum\": dem_vec.values,\n",
    "            },\n",
    "            index=price_bins,\n",
    "        )\n",
    "        out.append((name, slice_df))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "def group_slices_from_parquet(\n",
    "    parquet_path: str | Path,\n",
    "    areas: List[str],\n",
    "    *,\n",
    "    price_step: float = 0.01,\n",
    "    tz: str = \"Asia/Tokyo\",\n",
    ") -> Dict[pd.Timestamp, List[Tuple[str, pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    Read one Parquet file, build per-area MultiBidCurve objects,\n",
    "    then aggregate **per timestamp** by group-ID.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        key   = pd.Timestamp (30-min slot)\n",
    "        value = list of (combined_name, curve_slice_df)\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------- load regions\n",
    "    panels: List[MultiBidCurve] = [\n",
    "        load_curves_rows(\n",
    "            parquet_path,\n",
    "            area=area,\n",
    "            price_step=price_step,\n",
    "            tz=tz,\n",
    "        )\n",
    "        for area in areas\n",
    "    ]\n",
    "\n",
    "    # sanity: ensure identical bins across regions\n",
    "    bins0 = panels[0].bins\n",
    "    for p in panels[1:]:\n",
    "        if not np.array_equal(bins0, p.bins):\n",
    "            raise ValueError(\"Price grids differ across regions; resample first.\")\n",
    "\n",
    "    # union of all timestamps\n",
    "    all_ts = sorted(set().union(*(p.supply.index for p in panels)))\n",
    "\n",
    "    time_dict: Dict[pd.Timestamp, List[Tuple[str, pd.DataFrame]]] = {}\n",
    "\n",
    "    for ts in all_ts:\n",
    "        combined = _aggregate_slice(panels, ts, bins0)\n",
    "        if combined:                     # skip slots with no data anywhere\n",
    "            time_dict[ts] = combined\n",
    "\n",
    "    return time_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d218d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
